{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dcfc541",
   "metadata": {},
   "source": [
    "**Basic Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60fac791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class basicLoader(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=32, num_workers=4):\n",
    "        super().__init__()\n",
    "        self.batch_size=batch_size\n",
    "        self.num_workers=num_workers\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.dataset_train = datasets.FashionMNIST(root='root', train=True, download=True, transform=transforms.ToTensor())\n",
    "        self.dataset_test = datasets.FashionMNIST(root='root', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "def train_dataloader(self):\n",
    "    return DataLoader(dataset=self.dataset_train, batch_size=self.batch_size, shuffle=True, drop_last=True, num_workers=self.num_workers)\n",
    "\n",
    "def test_dataloader(self):\n",
    "    return DataLoader(dataset=self.dataset_test, batch_size=self.batch_size, shuffle=False, drop_last=True, num_workers=self.num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c4d0ec",
   "metadata": {},
   "source": [
    "**Custom Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7332272d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "import torch\n",
    "\n",
    "class customLoader(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size=32, num_workers=4, root_dir=\"animals/animals/animals/\"):\n",
    "        super().__init__()\n",
    "        self.batch_size=batch_size\n",
    "        self.num_workers=num_workers\n",
    "        self.root_dir = root_dir\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.Resize(300),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.RandomVerticalFlip(0.5),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.test_transform = transforms.Compose([\n",
    "            transforms.Resize(300),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        full_dataset = datasets.ImageFolder(root=self.root_dir, transform=None)\n",
    "        total_len = len(full_dataset)\n",
    "        val_len = int(total_len * 0.2)\n",
    "        train_len = total_len - val_len\n",
    "\n",
    "        subset_train_idx, subset_val_idx = random_split(\n",
    "            full_dataset, [train_len, val_len],\n",
    "            generator=torch.Generator().manual_seed(42)\n",
    "        )\n",
    "        train_indices = subset_train_idx.indices\n",
    "        val_indices = subset_val_idx.indices\n",
    "\n",
    "        train_folder   = datasets.ImageFolder(root=self.root_dir, transform=self.train_transform)\n",
    "        test_folder    = datasets.ImageFolder(root=self.root_dir, transform=self.test_transform)\n",
    "\n",
    "        self.train_dataset = Subset(train_folder, train_indices)\n",
    "        self.val_dataset   = Subset(test_folder,  val_indices)\n",
    "\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset=self.train_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True, num_workers=self.num_workers)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(dataset=self.val_dataset, batch_size=self.batch_size, shuffle=False, drop_last=True, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc890d7e",
   "metadata": {},
   "source": [
    "**Basic Net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim, nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "\n",
    "class basicEncoder(pl.LightningModule):\n",
    "    def __init__(self, num_classes=90):\n",
    "        super().__init__()\n",
    "        self.num_classes=num_classes\n",
    "        in_channels = 3\n",
    "        out_channels = [64,128,256,512]\n",
    "        kernel_size = 3\n",
    "        stride = 2\n",
    "        padding = 1\n",
    "\n",
    "        conv_output_size = out_channels[-1] * (224 // (2**len(out_channels)))**2\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels[0], kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=out_channels[0], out_channels=out_channels[1], kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=out_channels[1], out_channels=out_channels[2], kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels[2]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=out_channels[2], out_channels=out_channels[3], kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels[3]),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(conv_output_size,512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.classifier = nn.Linear(256,self.num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.training_acc = torchmetrics.Accuracy(task='multiclass', num_classes=self.num_classes)\n",
    "        self.val_acc = torchmetrics.Accuracy(task='multiclass', num_classes=self.num_classes)\n",
    "\n",
    "        self.training_f1 = torchmetrics.F1Score(task='multiclass', num_classes=self.num_classes)\n",
    "        self.val_f1 = torchmetrics.F1Score(task='multiclass', num_classes=self.num_classes)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.AdamW(self.parameters(), lr=1e-4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, training_batch, batch_idx):\n",
    "        x, y = training_batch\n",
    "        y_hat = self(x.float())\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        y_hat = F.softmax(y_hat, dim=1)\n",
    "\n",
    "        self.log('training_loss', loss, on_epoch=True, on_step=True)\n",
    "        self.training_acc.update(y_hat, y)\n",
    "        self.log('training_acc', self.training_acc, on_epoch=True, on_step=False)\n",
    "        self.training_f1.update(y_hat, y)\n",
    "        self.log('training_f1', self.training_f1, on_epoch=True, on_step=False)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x, y = val_batch\n",
    "        y_hat = self(x.float())\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        y_hat = F.softmax(y_hat, dim=1)\n",
    "\n",
    "        self.log('val_loss', loss, on_epoch=True, on_step=True)\n",
    "        self.val_acc.update(y_hat, y)\n",
    "        self.log('val_acc', self.val_acc, on_epoch=True, on_step=False)\n",
    "        self.val_f1.update(y_hat, y)\n",
    "        self.log('val_f1', self.val_f1, on_epoch=True, on_step=False)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54c7ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim, nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class AutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super().__init__()\n",
    "        in_channels = 3\n",
    "        kernel_size = 3\n",
    "        stride = 2\n",
    "        padding = 1\n",
    "        output_padding = 1\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,  64, kernel_size, stride, padding),\n",
    "            nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size, stride, padding),\n",
    "            nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size, stride, padding),\n",
    "            nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size, stride, padding),\n",
    "            nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
    "        )\n",
    "        conv_output_size = 512 * 14 * 14\n",
    "\n",
    "        self.enc_latent = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(conv_output_size, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, latent_dim),\n",
    "        )\n",
    "\n",
    "        self.dec_latent = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 512 * 14 * 14),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, kernel_size, stride, padding, output_padding),\n",
    "            nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size, stride, padding, output_padding),\n",
    "            nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(128,  64, kernel_size, stride, padding, output_padding),\n",
    "            nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(64,   3,  kernel_size, stride, padding, output_padding),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.enc_latent(x)\n",
    "        x = self.dec_latent(x)\n",
    "        x = x.view(-1, 512, 14, 14)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.AdamW(self.parameters(), lr=1e-4)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        x_hat = self(x)\n",
    "        loss = self.loss_fn(x_hat, x)\n",
    "        self.log('train_loss', loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        x_hat = self(x)\n",
    "        loss = self.loss_fn(x_hat, x)\n",
    "        self.log('val_loss', loss, prog_bar=True)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0ed4ab",
   "metadata": {},
   "source": [
    "**Trening**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac916414",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "model = basicEncoder()\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"model\")\n",
    "trainer = pl.Trainer(logger = logger, max_epochs = 15, log_every_n_steps =1)\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9f7299",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cd0abb",
   "metadata": {},
   "source": [
    "**Visualize reconstructions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f6bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_reconstructions(model, dataloader, device='cpu', num_images=8):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            x, _ = batch\n",
    "            x = x.to(device)\n",
    "            x_hat = model(x)\n",
    "            x = x.cpu()\n",
    "            x_hat = x_hat.cpu()\n",
    "            break\n",
    "    \n",
    "    n = min(num_images, x.size(0))\n",
    "    plt.figure(figsize=(n * 2, 4))\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Oryginał\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        img = x[i].permute(1, 2, 0).numpy()\n",
    "        plt.imshow(img)\n",
    "        ax.axis('off')\n",
    "        if i == 0:\n",
    "            ax.set_title('Original')\n",
    "        \n",
    "        # Rekonstrukcja\n",
    "        ax = plt.subplot(2, n, n + i + 1)\n",
    "        recon = x_hat[i].permute(1, 2, 0).numpy()\n",
    "        plt.imshow(recon)\n",
    "        ax.axis('off')\n",
    "        if i == 0:\n",
    "            ax.set_title('Reconstruction')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "dataset = customLoader()\n",
    "dataset.setup()\n",
    "visualize_reconstructions(model, dataset.val_dataloader(), device='cuda', num_images=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcd88d7",
   "metadata": {},
   "source": [
    "**Model pretrenowany**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torch import optim, nn\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model = models.efficientnet_b4(pretrained=True)\n",
    "\n",
    "class SneakerModel(pl.LightningModule):\n",
    "  def __init__(self, num_classes=50):\n",
    "    super().__init__()\n",
    "    layers = list(model.children())\n",
    "    self.backbone = nn.Sequential(*layers[:-1])\n",
    "\n",
    "    self.avgpool = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "    self.dropout = nn.Dropout(p=0.4)\n",
    "    self.fc1 = nn.LazyLinear(500)\n",
    "    self.fc2 = nn.Linear(500,num_classes)\n",
    "\n",
    "\n",
    "    self.loss_fn = nn.CrossEntropyLoss()\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "    self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "    self.val_acc = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)\n",
    "    self.train_macro_f1 = torchmetrics.F1Score(num_classes=num_classes, task=\"multiclass\", average='macro')\n",
    "    self.val_macro_f1 = torchmetrics.F1Score(num_classes=num_classes, task=\"multiclass\", average='macro')\n",
    "\n",
    "  def forward(self, x):\n",
    "    self.backbone.eval()\n",
    "    with torch.no_grad():\n",
    "      x = self.backbone(x)\n",
    "    x = self.avgpool(x).flatten(1)\n",
    "    x = self.dropout(x)\n",
    "    x = self.fc1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.fc2(x)\n",
    "    return x\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    return optim.AdamW(self.parameters(), lr=1e-4)\n",
    "\n",
    "  def training_step(self, train_batch, batch_idx):\n",
    "    inputs, labels = train_batch\n",
    "    y_hat = self(inputs.float())\n",
    "    loss = self.loss_fn(y_hat, labels)\n",
    "    y_hat = F.softmax(y_hat, dim=1)\n",
    "\n",
    "    self.log('train_loss', loss, on_step=True, on_epoch=True)\n",
    "    self.train_acc(y_hat, labels)\n",
    "    self.log('train_acc', self.train_acc, on_epoch=True, on_step=False)\n",
    "    self.train_macro_f1(y_hat, labels)\n",
    "    self.log('train_macro_f1', self.train_macro_f1, on_epoch=True, on_step=False)\n",
    "\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self, val_batch, val_idx):\n",
    "    inputs, labels = val_batch\n",
    "    y_hat = self(inputs.float())\n",
    "    loss = self.loss_fn(y_hat, labels)\n",
    "    y_hat = F.softmax(y_hat, dim=1)\n",
    "\n",
    "    self.log('val_loss', loss, on_step=True, on_epoch=True)\n",
    "    self.val_acc(y_hat, labels)\n",
    "    self.log('val_acc', self.val_acc, on_epoch=True, on_step=False)\n",
    "    self.val_macro_f1(y_hat, labels)\n",
    "    self.log('val_macro_f1', self.val_macro_f1, on_epoch=True, on_step=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb110bf9",
   "metadata": {},
   "source": [
    "**Wizualizacja sieci**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9697f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from torchview import draw_graph\n",
    "\n",
    "graphviz.set_jupyter_format('png')\n",
    "model_graph = draw_graph(\n",
    "    model,\n",
    "    input_size=(BATCH_SIZE, IMG_CH, IMG_SIZE, IMG_SIZE),\n",
    "    device='meta',\n",
    "    expand_nested=True\n",
    ")\n",
    "model_graph.resize_graph(scale=1.5)\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3725e7eb",
   "metadata": {},
   "source": [
    "**Transformer z Macierzą pomyłek**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cc5012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchmetrics\n",
    "from transformers import SwinModel\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "class SneakerModel(pl.LightningModule):\n",
    "    def __init__(self, num_classes=50, lr=1e-4):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.lr = lr\n",
    "\n",
    "        self.backbone = SwinModel.from_pretrained(\n",
    "            \"microsoft/swin-tiny-patch4-window7-224\",\n",
    "            add_pooling_layer=True\n",
    "        )\n",
    "        hidden_size = self.backbone.config.hidden_size\n",
    "\n",
    "        for p in self.backbone.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_size, 500)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(500, self.num_classes)\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.val_acc   = torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_acc  = torchmetrics.Accuracy(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "        self.train_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.val_f1   = torchmetrics.F1Score(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_f1  = torchmetrics.F1Score(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "        self.train_cm = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.val_cm   = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=self.num_classes)\n",
    "        self.test_cm  = torchmetrics.ConfusionMatrix(task=\"multiclass\", num_classes=self.num_classes)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.AdamW(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.backbone(pixel_values=x)\n",
    "        x = outputs.last_hidden_state[:, 0, :]\n",
    "        x = self.relu(self.fc1(x))\n",
    "        logits = self.fc2(x)\n",
    "        return logits\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x.float())\n",
    "        loss = self.loss_fn(logits, y)\n",
    "\n",
    "        probs = nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.train_acc.update(probs, y)\n",
    "        self.log('train_acc', self.train_acc, on_step=False, on_epoch=True)\n",
    "        self.train_f1.update(probs, y)\n",
    "        self.log('train_f1', self.train_f1, on_step=False, on_epoch=True)\n",
    "        self.train_cm.update(probs, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x.float())\n",
    "        loss = self.loss_fn(logits, y)\n",
    "\n",
    "        probs = nn.functional.softmax(logits, dim=1)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.val_acc.update(probs, y)\n",
    "        self.log('val_acc', self.val_acc, on_step=False, on_epoch=True)\n",
    "        self.val_f1.update(probs, y)\n",
    "        self.log('val_f1', self.val_f1, on_step=False, on_epoch=True)\n",
    "        self.val_cm.update(probs, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        logits = self(x.float())\n",
    "        loss = self.loss_fn(logits, y)\n",
    "\n",
    "        probs = nn.functional.softmax(logits, dim=1)\n",
    "        self.log('test_loss', loss, on_step=False, on_epoch=True)\n",
    "        self.test_acc.update(probs, y)\n",
    "        self.log('test_acc', self.test_acc, on_step=False, on_epoch=True)\n",
    "        self.test_f1.update(probs, y)\n",
    "        self.log('test_f1', self.test_f1, on_step=False, on_epoch=True)\n",
    "        self.test_cm.update(probs, y)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"val_acc\", self.val_acc.compute(), prog_bar=True)\n",
    "        self.log(\"val_f1\",  self.val_f1.compute(),  prog_bar=True)\n",
    "\n",
    "        cm = self.val_cm.compute().cpu().numpy()\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        sns.heatmap(\n",
    "            cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False,\n",
    "            xticklabels=[str(i) for i in range(self.num_classes)],\n",
    "            yticklabels=[str(i) for i in range(self.num_classes)],\n",
    "            ax=ax\n",
    "        )\n",
    "        ax.set_ylabel(\"True\")\n",
    "        ax.set_xlabel(\"Predicted\")\n",
    "        ax.set_title(f\"Val Confusion Matrix (epoch {self.current_epoch})\")\n",
    "\n",
    "        self.logger.experiment.add_figure(\"val_confusion_matrix\", fig, self.current_epoch)\n",
    "        plt.close(fig)\n",
    "\n",
    "        self.val_acc.reset()\n",
    "        self.val_f1.reset()\n",
    "        self.val_cm.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807427cd",
   "metadata": {},
   "source": [
    "**Skipped connections U-net**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82accaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class unet(pl.LightningModule):\n",
    "    def __init__(self, num_class=90):\n",
    "        super().__init__()\n",
    "\n",
    "        self.e11 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.e12 = nn.Conv2d(64, 64, kernel_size=3, padding=1) \n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "\n",
    "        self.e21 = nn.Conv2d(64, 128, kernel_size=3, padding=1) \n",
    "        self.e22 = nn.Conv2d(128, 128, kernel_size=3, padding=1) \n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.e31 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.e32 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.e41 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.e42 = nn.Conv2d(512, 512, kernel_size=3, padding=1) \n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) \n",
    "\n",
    "        self.e51 = nn.Conv2d(512, 1024, kernel_size=3, padding=1) \n",
    "        self.e52 = nn.Conv2d(1024, 1024, kernel_size=3, padding=1) \n",
    "\n",
    "        self.upconv1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.d11 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.d12 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.d21 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.d22 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.d31 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.d32 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.d41 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.d42 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.outconv = nn.Conv2d(64, num_class, kernel_size=1)\n",
    "\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.AdamW(self.parameters(), lr=1e-4)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        xe11 = F.relu(self.e11(x))\n",
    "        xe12 = F.relu(self.e12(xe11))\n",
    "        xp1 = self.pool1(xe12)\n",
    "\n",
    "        xe21 = F.relu(self.e21(xp1))\n",
    "        xe22 = F.relu(self.e22(xe21))\n",
    "        xp2 = self.pool2(xe22)\n",
    "\n",
    "        xe31 = F.relu(self.e31(xp2))\n",
    "        xe32 = F.relu(self.e32(xe31))\n",
    "        xp3 = self.pool3(xe32)\n",
    "\n",
    "        xe41 = F.relu(self.e41(xp3))\n",
    "        xe42 = F.relu(self.e42(xe41))\n",
    "        xp4 = self.pool4(xe42)\n",
    "\n",
    "        xe51 = F.relu(self.e51(xp4))\n",
    "        xe52 = F.relu(self.e52(xe51))\n",
    "        \n",
    "        # Decoder\n",
    "        xu1 = self.upconv1(xe52)\n",
    "        xu11 = torch.cat([xu1, xe42], dim=1)\n",
    "        xd11 = F.relu(self.d11(xu11))\n",
    "        xd12 = F.relu(self.d12(xd11))\n",
    "\n",
    "        xu2 = self.upconv2(xd12)\n",
    "        xu22 = torch.cat([xu2, xe32], dim=1)\n",
    "        xd21 = F.relu(self.d21(xu22))\n",
    "        xd22 = F.relu(self.d22(xd21))\n",
    "\n",
    "        xu3 = self.upconv3(xd22)\n",
    "        xu33 = torch.cat([xu3, xe22], dim=1)\n",
    "        xd31 = F.relu(self.d31(xu33))\n",
    "        xd32 = F.relu(self.d32(xd31))\n",
    "\n",
    "        xu4 = self.upconv4(xd32)\n",
    "        xu44 = torch.cat([xu4, xe12], dim=1)\n",
    "        xd41 = F.relu(self.d41(xu44))\n",
    "        xd42 = F.relu(self.d42(xd41))\n",
    "\n",
    "        # Output layer\n",
    "        out = self.outconv(xd42)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        inputs, labels = train_batch\n",
    "        y_hat = self(inputs.float())\n",
    "        loss = self.loss_fn(y_hat, labels)\n",
    "        y_hat = F.softmax(y_hat, dim=1)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c33e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "from torchview import draw_graph\n",
    "model = unet()\n",
    "\n",
    "graphviz.set_jupyter_format('png')\n",
    "model_graph = draw_graph(\n",
    "    model,\n",
    "    input_size=(1, 3, 224, 224),\n",
    "    device='cpu'\n",
    ")\n",
    "model_graph.resize_graph(scale=1.5)\n",
    "model_graph.visual_graph"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
